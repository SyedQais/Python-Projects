# AI Web Scraper

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.3-FF4B4B)
![Selenium](https://img.shields.io/badge/Selenium-4.0-43B02A)
![Gemini](https://img.shields.io/badge/Google-Gemini_Flash-8E75B2)

## Overview

**AI Web Scraper** is an intelligent web scraping tool that extracts structured data from websites using **Natural Language Processing (NLP)**.

Unlike traditional scrapers that rely on rigid CSS or XPath selectors, this tool allows users to describe what they want in **plain English** (e.g., *"Extract all product names and prices"*).

The project uses **Selenium** for rendering JavaScript-heavy pages, **BeautifulSoup** for cleaning the DOM, and **Google Gemini (Flash model)** for AI-powered extraction from raw HTML.

---

## Features

* **Dynamic Scraping** – Handles JavaScript-rendered websites using Selenium
* **AI-Powered Parsing** – Extracts data via natural language prompts using Google Gemini
* **DOM Cleaning** – Removes scripts, styles, and unused tags to optimize token usage
* **Streamlit UI** – Interactive interface for scraping, viewing DOM, and parsing results

---

## Tech Stack

| Component | Technology                         |
| --------- | ---------------------------------- |
| Frontend  | Streamlit                          |
| Scraping  | Selenium, BeautifulSoup4, HTML5Lib |
| AI Model  | Google Gemini (Flash)              |
| Config    | python-dotenv                      |

---

## Installation & Setup

### 1️⃣ Clone the Repository

```bash
git clone https://github.com/SyedQais/Web-Scrapper-AI.git
cd Web-Scrapper-AI
```

---

### 2️⃣ Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

---

### 3️⃣ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4️⃣ Download ChromeDriver

* Check your Chrome version: `chrome://settings/help`
* Download the matching ChromeDriver from:
  [https://chromedriver.chromium.org/downloads](https://chromedriver.chromium.org/downloads)
* Place the driver in:

  * Project root **or**
  * System PATH

---

### 5️⃣ Configure Google Gemini API Key

Create a `.env` file in the project root:

```env
GOOGLE_API_KEY=your_api_key_here
```

---

## ▶️ Usage

Run the Streamlit application:

```bash
streamlit run app.py
```

### How to Use the App

1. Enter the target **website URL**
2. Click **Scrape Website**
3. View the cleaned DOM content
4. Enter a **natural language prompt**

   * Example:
     `Extract product names and prices`
5. Get structured output generated by AI

---

## How It Works

1. Selenium loads and renders the webpage
2. BeautifulSoup cleans the HTML DOM
3. Cleaned HTML is sent to Google Gemini
4. Gemini extracts data based on user prompt
5. Results are displayed in the Streamlit UI

---

## Project Structure

```text
Web-Scrapper-AI/
│
├── main.py                # Main Streamlit app
├── scraper/               # Selenium + DOM cleaning logic
├── gemini_parse/          # Google Gemini integration
├── requirements.txt       # Python dependencies
└── README.md              # Documentation
```

---

## Portfolio Note

This project demonstrates:

* AI-assisted data extraction
* Real-world web scraping with dynamic pages
* LLM integration with structured outputs
* Practical use of Streamlit for rapid prototyping

Ideal for showcasing skills in:
**Python, Selenium, NLP, LLMs, and AI-driven automation**

---

## Disclaimer

This project is for **educational and research purposes only**.
Always respect website **Terms of Service** and **robots.txt** policies.

---

## Author

**Syed Qais Abbas**
GitHub: [https://github.com/SyedQais](https://github.com/SyedQais)

---

## Support

If you find this project useful, consider giving it a **star ⭐** on GitHub!
